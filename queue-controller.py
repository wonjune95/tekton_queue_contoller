import time
import threading
import fnmatch
import copy
import json
import datetime
from kubernetes import client, config, watch
from kubernetes.client.rest import ApiException

# =========================================================
# [ì„¤ì •]
NAMESPACE_PATTERN = "*-cicd"  # ê´€ë¦¬ ëŒ€ìƒ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
DEFAULT_LIMIT = 10            # ê¸°ë³¸ ë™ì‹œ ì‹¤í–‰ ì œí•œ
MANAGED_LABEL_KEY = "queue.tekton.dev/managed"
MANAGED_LABEL_VAL = "yes"
# =========================================================

# [í•µì‹¬ ì•„í‚¤í…ì²˜] API í˜¸ì¶œì„ ì—†ì• ê¸° ìœ„í•œ ë¡œì»¬ ìºì‹œ ì €ì¥ì†Œ
# Key: "{namespace}/{name}", Value: PipelineRun Object (Dict)
local_cache = {}
cache_lock = threading.Lock()

try:
    config.load_incluster_config()
except:
    config.load_kube_config()

api = client.CustomObjectsApi()

# ---------------------------------------------------------
# [ìœ í‹¸ë¦¬í‹°] ë¡œê·¸ ë° í¬ë§·íŒ…
# ---------------------------------------------------------
def log(msg):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{now}] {msg}", flush=True)

def print_dashboard(limit, running_cnt, pending_list):
    """
    í˜„ì¬ ìƒíƒœë¥¼ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ëŒ€ì‹œë³´ë“œ ë¡œê·¸
    """
    bar_length = 20
    filled_length = int(bar_length * running_cnt // limit) if limit > 0 else 0
    bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
    
    log("="*50)
    log(f"ğŸ“Š [ì‹œìŠ¤í…œ í˜„í™©] Limit: {limit}")
    log(f"ğŸŸ¢ ì‹¤í–‰ ì¤‘ : {running_cnt:2d} / {limit:2d} |{bar}| ({running_cnt/limit*100 if limit else 0:.1f}%)")
    log(f"â³ ëŒ€ê¸° ì¤‘ : {len(pending_list):2d} ê°œ")
    
    if len(pending_list) > 0:
        log("-" * 50)
        log("   [ëŒ€ê¸°ì—´ Top 3]")
        for idx, item in enumerate(pending_list[:3]):
            ns = item['metadata']['namespace']
            name = item['metadata']['name']
            log(f"   {idx+1}. {ns}/{name}")
    log("="*50)

# ---------------------------------------------------------
# [í•µì‹¬ ë¡œì§] ìºì‹œ ê¸°ë°˜ ìƒíƒœ ì¡°íšŒ (API í˜¸ì¶œ 0íšŒ)
# ---------------------------------------------------------
def is_target_namespace(namespace):
    return fnmatch.fnmatch(namespace, NAMESPACE_PATTERN)

def get_queue_status_from_cache():
    """
    etcdë¥¼ ì¡°íšŒí•˜ì§€ ì•Šê³ , ë©”ëª¨ë¦¬ì— ìˆëŠ” local_cacheë¥¼ ë’¤ì ¸ì„œ ê³„ì‚°í•¨.
    ë…¼ë¬¸ì˜ í•µì‹¬: O(N) API Call -> O(1) Memory Access
    """
    running_cnt = 0
    managed_pending_list = []

    with cache_lock:
        for key, item in local_cache.items():
            ns = item['metadata']['namespace']
            
            # 1. ê´€ë¦¬ ëŒ€ìƒ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì¸ì§€ í™•ì¸
            if not is_target_namespace(ns): 
                continue

            # 2. ìƒíƒœ í™•ì¸
            spec_status = item.get('spec', {}).get('status')
            conditions = item.get('status', {}).get('conditions', [])
            
            # ì´ë¯¸ ì™„ë£Œëœ(Succeeded/Failed/Cancelled) íŒŒì´í”„ë¼ì¸ì€ ì¹´ìš´íŠ¸ ì œì™¸
            if conditions and conditions[0]['status'] != 'Unknown':
                continue
            
            # ì‹¤í–‰ ì¤‘ vs ëŒ€ê¸° ì¤‘ ë¶„ë¥˜
            if spec_status != 'PipelineRunPending':
                running_cnt += 1
            else:
                # ë¼ë²¨ì´ ìˆëŠ” ì •ì‹ ëŒ€ê¸°ì—´ë§Œ í¬í•¨
                labels = item['metadata'].get('labels', {})
                if labels.get(MANAGED_LABEL_KEY) == MANAGED_LABEL_VAL:
                    managed_pending_list.append(item)

    # ë¨¼ì € ìƒì„±ëœ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (FIFO)
    managed_pending_list.sort(key=lambda x: x['metadata']['creationTimestamp'])
    return running_cnt, managed_pending_list

def update_cache(event_type, obj):
    """
    Watcherë¡œë¶€í„° ì´ë²¤íŠ¸ë¥¼ ë°›ì•„ ìºì‹œë¥¼ í˜„í–‰í™”í•˜ëŠ” í•¨ìˆ˜
    """
    ns = obj['metadata']['namespace']
    name = obj['metadata']['name']
    key = f"{ns}/{name}"

    with cache_lock:
        if event_type == 'DELETED':
            if key in local_cache:
                del local_cache[key]
                # log(f"[Cache] ì‚­ì œë¨: {key}") # ë„ˆë¬´ ì‹œë„ëŸ¬ìš°ë©´ ì£¼ì„ ì²˜ë¦¬
        else:
            local_cache[key] = obj
            # log(f"[Cache] ì—…ë°ì´íŠ¸: {key}") # ë””ë²„ê¹…ìš©

# ---------------------------------------------------------
# [K8s ì¡°ì‘] ì‹¤ì œ ë³€ê²½ì´ í•„ìš”í•  ë•Œë§Œ í˜¸ì¶œ (API í˜¸ì¶œ ìµœì†Œí™”)
# ---------------------------------------------------------
def get_limit_from_crd():
    try:
        obj = api.get_cluster_custom_object('tekton.devops', 'v1', 'globallimits', 'tekton-queue-limit')
        return int(obj['spec']['maxPipelines'])
    except:
        return DEFAULT_LIMIT

def patch_status(name, namespace, status_val):
    try:
        body = {'spec': {'status': status_val}}
        api.patch_namespaced_custom_object(
            'tekton.dev', 'v1', namespace, 'pipelineruns', name, body
        )
        action = "ğŸš€ ì‹¤í–‰ ì‹œì‘" if status_val is None else "â›” ëŒ€ê¸° ì „í™˜"
        log(f"[{action}] {namespace}/{name}")
        return True
    except ApiException as e:
        log(f"[Patch ì‹¤íŒ¨] {e}")
        return False
    except:
        return False

def add_managed_label(name, namespace):
    try:
        body = {'metadata': {'labels': {MANAGED_LABEL_KEY: MANAGED_LABEL_VAL}}}
        api.patch_namespaced_custom_object('tekton.dev', 'v1', namespace, 'pipelineruns', name, body)
    except: pass

def recreate_as_pending(original_obj):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼ - ìƒëµ ì—†ì´ ì‚¬ìš©í•˜ì„¸ìš”)
    ns = original_obj['metadata']['namespace']
    name = original_obj['metadata']['name']
    log(f"ğŸ‘® [ê°•ì œ ì§‘í–‰] {ns}/{name} -> ì¿¼í„° ì´ˆê³¼ë¡œ ì¦‰ì‹œ ì‚­ì œ í›„ ëŒ€ê¸°ì—´ ì´ë™")

    try:
        api.delete_namespaced_custom_object(
            'tekton.dev', 'v1', ns, 'pipelineruns', name,
            body=client.V1DeleteOptions(propagation_policy='Background')
        )
    except: return

    new_obj = copy.deepcopy(original_obj)
    # ë©”íƒ€ë°ì´í„° ì •ë¦¬
    for key in ['resourceVersion', 'uid', 'creationTimestamp', 'ownerReferences', 'generation']:
        if key in new_obj['metadata']: del new_obj['metadata'][key]
    
    if 'status' in new_obj: del new_obj['status']
    if 'spec' not in new_obj: new_obj['spec'] = {}
    new_obj['spec']['status'] = 'PipelineRunPending'

    if 'labels' not in new_obj['metadata']: new_obj['metadata']['labels'] = {}
    new_obj['metadata']['labels'][MANAGED_LABEL_KEY] = MANAGED_LABEL_VAL

    base_name = name[:40]
    new_obj['metadata']['name'] = f"{base_name}-q{int(time.time())}"

    try:
        api.create_namespaced_custom_object('tekton.dev', 'v1', ns, 'pipelineruns', new_obj)
        log(f"âœ… [ì¬ë“±ë¡ ì™„ë£Œ] {ns}/{new_obj['metadata']['name']} (ìˆœë²ˆ ëŒ€ê¸°)")
    except Exception as e:
        log(f"ì¬ìƒì„± ì‹¤íŒ¨: {e}")

# ---------------------------------------------------------
# [Thread 1] ë§¤ë‹ˆì € (ì£¼ê¸°ì  ì‹¤í–‰ ë‹´ë‹¹)
# ---------------------------------------------------------
def manager_loop():
    log("ğŸ”§ ë§¤ë‹ˆì € ìŠ¤ë ˆë“œ ì‹œì‘ (ìŠ¤ì¼€ì¤„ë§ ì£¼ê¸°: 5ì´ˆ)")
    last_log_time = 0

    while True:
        try:
            limit = get_limit_from_crd() # ConfigMap ì¡°íšŒ (ê°€ë²¼ì›€)
            
            # [ì¤‘ìš”] API í˜¸ì¶œ ì—†ì´ ìºì‹œì—ì„œ ì¦‰ì‹œ ì¡°íšŒ
            running, pending = get_queue_status_from_cache()

            # ìƒíƒœê°€ ë³€í–ˆê±°ë‚˜ ì¼ì • ì‹œê°„ì´ ì§€ë‚¬ìœ¼ë©´ ë¡œê·¸ ì¶œë ¥
            if len(pending) > 0 or abs(time.time() - last_log_time) > 60:
                print_dashboard(limit, running, pending)
                last_log_time = time.time()

            # ìŠ¤ì¼€ì¤„ë§ ë¡œì§
            if running < limit and pending:
                slots = limit - running
                to_run = pending[:slots]

                for target in to_run:
                    t_name = target['metadata']['name']
                    t_ns = target['metadata']['namespace']
                    
                    # ì‹¤í–‰ ì‹œë„
                    if patch_status(t_name, t_ns, None):
                        running += 1
                        slots -= 1
                        # ìºì‹œ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (API Watch ì˜¤ê¸° ì „ì— ë¯¸ë¦¬ ë°˜ì˜í•´ë‘ê¸°)
                        with cache_lock:
                            key = f"{t_ns}/{t_name}"
                            if key in local_cache:
                                if 'spec' not in local_cache[key]: local_cache[key]['spec'] = {}
                                local_cache[key]['spec']['status'] = None # Pending í•´ì œ
                        
        except Exception as e:
            log(f"ë§¤ë‹ˆì € ì—ëŸ¬: {e}")
        
        time.sleep(5)

# ---------------------------------------------------------
# [Thread 2] ì™“ì³ (ìºì‹œ ë™ê¸°í™” ë° ë‹¨ì†)
# ---------------------------------------------------------
def watcher_loop():
    log("ğŸ‘€ ì™“ì³ ìŠ¤ë ˆë“œ ì‹œì‘ (Informer Pattern)")
    resource_version = None

    while True:
        try:
            # 1. [List] ìµœì´ˆ 1íšŒ ì „ì²´ ë™ê¸°í™”
            if resource_version is None:
                log("ğŸ“¡ í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì „ì²´ ë™ê¸°í™” ì¤‘... (List)")
                raw_resp = api.list_cluster_custom_object(
                    'tekton.dev', 'v1', 'pipelineruns', _preload_content=False
                )
                data = json.loads(raw_resp.data)
                resource_version = data['metadata']['resourceVersion']
                
                # ì´ˆê¸° ìºì‹œ êµ¬ì¶•
                with cache_lock:
                    local_cache.clear()
                    for item in data.get('items', []):
                        key = f"{item['metadata']['namespace']}/{item['metadata']['name']}"
                        local_cache[key] = item
                
                log(f"âœ… ë™ê¸°í™” ì™„ë£Œ. ìºì‹œ í•­ëª©: {len(local_cache)}ê°œ. ê°ì‹œ ì‹œì‘.")

            # 2. [Watch] ë³€ê²½ ì‚¬í•­ ìŠ¤íŠ¸ë¦¬ë°
            w = watch.Watch()
            stream = w.stream(
                api.list_cluster_custom_object,
                'tekton.dev', 'v1', 'pipelineruns',
                resource_version=resource_version,
                timeout_seconds=0
            )

            for event in stream:
                obj = event['object']
                etype = event['type']
                
                # ë‹¤ìŒ ì¬ì—°ê²°ì„ ìœ„í•´ ë²„ì „ ê°±ì‹ 
                resource_version = obj['metadata']['resourceVersion']

                # [í•µì‹¬] 1. ìºì‹œ ë¬´ì¡°ê±´ ìµœì‹ í™”
                update_cache(etype, obj)

                # [í•µì‹¬] 2. ê³¼ì† ë‹¨ì† ë¡œì§ (ì—¬ê¸°ì„œë„ API ì¡°íšŒ ì•ˆ í•¨!)
                if etype == 'ADDED' or etype == 'MODIFIED':
                    ns = obj['metadata']['namespace']
                    name = obj['metadata']['name']
                    
                    if not is_target_namespace(ns): continue
                    
                    # ì´ë¯¸ ëë‚œê±°ë©´ íŒ¨ìŠ¤
                    conds = obj.get('status', {}).get('conditions', [])
                    if conds and conds[0]['status'] != 'Unknown': continue

                    # Pending ìƒíƒœë©´ íŒ¨ìŠ¤
                    spec_status = obj.get('spec', {}).get('status')
                    if spec_status == 'PipelineRunPending': continue

                    # ë¼ë²¨ ë¶€ì°©
                    if MANAGED_LABEL_KEY not in obj['metadata'].get('labels', {}):
                        add_managed_label(name, ns)

                    # ì¿¼í„° ì²´í¬ (ìºì‹œ ê¸°ë°˜)
                    limit = get_limit_from_crd()
                    running, _ = get_queue_status_from_cache()

                    # ë‚´ ìì‹ ì´ Runningì— í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, limitë³´ë‹¤ í¬ë©´ ë‚´ê°€ ê³¼ì†ë²”ì„
                    if running > limit:
                        log(f"ğŸš¨ [ê³¼ì† ê°ì§€] {ns}/{name} (Running: {running} > Limit: {limit})")
                        success = patch_status(name, ns, 'PipelineRunPending')
                        if not success:
                            recreate_as_pending(obj)

        except ApiException as e:
            if e.status == 410: # Resource expired
                resource_version = None
            else:
                log(f"API ì—ëŸ¬: {e}")
                time.sleep(2)
        except Exception as e:
            log(f"ì™“ì³ ì—ëŸ¬: {e}")
            resource_version = None
            time.sleep(2)

if __name__ == "__main__":
    t1 = threading.Thread(target=manager_loop, daemon=True)
    t2 = threading.Thread(target=watcher_loop, daemon=True)
    t1.start(); t2.start()
    
    try:
        while True: time.sleep(1)
    except KeyboardInterrupt:
        log("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
